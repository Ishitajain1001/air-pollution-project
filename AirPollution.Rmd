---
title: 'Air Pollution Project'
author: 'Ishita Jain'
date: "2024-08-20"
output:
  pdf_document: default
  html_document: default
---

```{r global_options, include=FALSE}
knitr::opts_chunk$set(R.options = list(max.print=100))
suppressPackageStartupMessages({
  library(tidyverse)
  library(tidymodels)
  library(kknn)
})
```

## Project: Air Pollution

Loading the data and packages needed.

```{r}
library(tidyverse)
library(tidymodels)
tidymodels_prefer()

dat <- read_csv("pm25_data.csv.gz")
```

## Title and Introduction

**For this data set, I looked at three different modeling approaches including Linear Regression, K-Nearest Neighbors, and Random Forest. In terms of the predictors chosen I looked at the different variables presented and found ones I thought might help predict the average PM2.5 concentration at the monitors. I then looked at which variables would appear to have a significant linear relationship by running different summaries on different recipes and used those for the rest of the models. I also ran a histogram on the nohs variable and saw that it was not normal so I applied a logarithmic transformation which helped significantly. I expect the RMSE of the model to be between 2 and 5.**

## Wrangling

```{r}
dat <- dat |>
  separate(col = id,
           into = c(NA, "monitor"))

hist(dat$nohs)
```

```{r}
dat <- dat |>
mutate(nohs = scale(nohs))
```

**One of the columns in the data, id, appeared to hold extraneous information so I separated the data and kept the monitor number for later application. The data set appeared to be in a tidy format so not much else was needed.**

## Results

```{r}
# Split into training and testing data sets
dat_split <- initial_split(dat)
dat_train <- training(dat_split)
dat_test <- testing(dat_split)
```

### Linear Regression

```{r}
rec <- dat_train |>
  recipe(value~CMAQ + aod + log_dist_to_prisec + log_nei_2008_pm25_sum_10000 + nohs) |>
  step_normalize(all_predictors()) |>
  step_scale(all_predictors())

lm_model <- linear_reg() |>
  set_engine("lm") |>
  set_mode("regression")

lm_wf <- workflow() |>
  add_recipe(rec) |>
  add_model(lm_model)

folds <- vfold_cv(dat_train, v = 10)
lm_res <- fit_resamples(lm_wf, resamples = folds, metrics = metric_set(rmse))
lm_metrics <- lm_res %>%
  collect_metrics() |>
  mutate(model = "linear regression")

lin_rmse = 2.1243151
```

### K-Nearest Neighbors

```{r}
knn_model <- nearest_neighbor(neighbors = tune("k")) %>%
  set_engine("kknn") %>%
  set_mode("regression")

knn_wf <- workflow() %>%
  add_model(knn_model) %>%
  add_recipe(rec)

knn_res <- tune_grid(knn_wf, resamples = folds,
                     grid = tibble(k = c(3, 5, 10, 15, 20, 25)),
                     metrics = metric_set(rmse))

knn_res %>%
  collect_metrics()
```

```{r}
knn_res %>%
  collect_metrics() %>%
  filter(.metric == "rmse") %>%
  ggplot(aes(k, mean)) +
  geom_point() +
  geom_line()
```

```{r}
#Thus k neighbors of 20 seem to have the best model since it has the lowest rmse

knn_model <- nearest_neighbor(neighbors = 20) %>%
  set_engine("kknn") %>%
  set_mode("regression")

knn_wf <- workflow() %>%
  add_model(knn_model) %>%
  add_recipe(rec)

knn_res <- fit_resamples(knn_wf, resamples = folds, metrics = metric_set(rmse))
k_metrics <- knn_res %>%
  collect_metrics() %>%
  filter(.metric == "rmse") %>%
  mutate(model = "k_NN")
k_20_rmse = 2.008735
```

### Random Forest Model

```{r}
rf_model <- rand_forest(mtry = tune("mtry"),
                        min_n = tune("min_n")) %>%
  set_engine("ranger") %>%
  set_mode("regression")

rf_wf <- workflow() %>%
  add_recipe(rec) %>%
  add_model(rf_model)

## Fit model over grid of tuning parameters
rf_res <- tune_grid(rf_wf, resamples = folds,
                    grid = expand.grid(mtry = c(1, 2, 5),
                                       min_n = c(3, 5)))
rf_res %>%
  collect_metrics()
```

```{r}
rf_res %>%
  show_best(metric = "rmse")
```

```{r}
rf_metrics <- rf_res |>
  collect_metrics() |>
  filter(.metric == "rmse") |>
  filter(mtry == 2 & min_n == 3) |>
  mutate(model = "random forest") |>
  arrange(mean)

randFor_rmse = 1.854144
```

### Summarizing Results

```{r}
combined <- bind_rows(lm_metrics, k_metrics, rf_metrics)

combined |>
  group_by(model) |>
  summarize(mean) |>
  rename("RMSE" = mean) |>
  arrange(RMSE)
```

```{r}
# Gather RMSE values into a data frame
rmse_df <- bind_rows(lm_res, knn_res, rf_res)

# Create a plot of the RMSE values for each model
ggplot(combined, aes(x = model, y = mean)) +
  geom_boxplot() +
  scale_y_continuous(limits = c(0, 5), expand = expansion(mult = c(0, 0.05))) +
  labs(x = "Model", y = "RMSE", title = "Comparison of Model Performance") +
  theme_bw()
```

```{r}
rf_model <- rand_forest(mtry = 5, min_n = 5) %>%
  set_engine("ranger") %>%
  set_mode("regression")

rf_wf <- workflow() %>%
  add_recipe(rec) %>%
  add_model(rf_model)

rf_fit <- rf_wf %>%
  fit(dat_train)

rf_pred <- predict(rf_fit, dat_test) %>%
  bind_cols(dat_test)

dat_test$differences <- rf_pred$.pred - dat_test$value

rf_rmse <- sqrt(mean(dat_test$differences^2, na.rm = TRUE))
rf_rmse
```

**Primarily I split the data into training and testing data sets with a 75-25 split. I created 2 different models all using the same recipe to test which approach works the best. They included linear regression, k-nearest neighbors and random forest. The model with the lowest RMSE appears to be the Random Forest model showing it is the best approach.**

## Discussion

```{r}
dat_test |>
  group_by(state) |>
  summarize(avg = mean(differences), n = n()) |>
  arrange(abs(avg))
```

1.  For the most part, the locations that are closest from observed values appear to be near a water source and opposite for the far ones. This might be due to the clarity of the air when it is near the coast.

2.  I do not think there are exact regions for the model that I have where they perform better or worse since they appear mainly scattered except for the coasts. I think information about the locations car pollution might be a strong predictor that could have helped.

3.  The model seems to be weaker when CMAQ and AOD are not included in the model with higher residuals.

4.  I do not think the model will perform quite well for Hawaii or Alaska since these states were left out of the data and the weather conditions are drastically different there compared to other US locations. It was very challenging for me to come up with a visualization for the rmse but I have learned to keep trying and experimenting to reach a conclusion. It performed as I expected but on the lower spectrum of what I thought for my models. I did this project on my own.
